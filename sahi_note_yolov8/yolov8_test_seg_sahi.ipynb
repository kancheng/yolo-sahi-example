{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# arrange an instance segmentation model for test\n",
    "from sahi.utils.yolov8 import (\n",
    "    download_yolov8s_model, download_yolov8s_seg_model\n",
    ")\n",
    "\n",
    "from sahi import AutoDetectionModel\n",
    "from sahi.utils.cv import read_image\n",
    "from sahi.utils.file import download_from_url\n",
    "from sahi.predict import get_prediction, get_sliced_prediction, predict\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "p = os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download YOLOV8S model to 'models/yolov8s.pt'\n",
    "# yolov8_seg_model_path = \"models/yolov8s-seg.pt\"\n",
    "yolov8_seg_model_path = \"yolov8n-seg.pt\"\n",
    "download_yolov8s_seg_model(yolov8_seg_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note : https://github.com/orgs/ultralytics/discussions/8121"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 listed files in folder: demo_data/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:   0%|                                                             | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 2 slices.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images:  33%|█████████████████▋                                   | 1/3 [00:00<00:01,  1.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction time is: 734.94 ms\n",
      "Performing prediction on 2 slices.\n",
      "Prediction time is: 117.23 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Performing inference on images: 100%|█████████████████████████████████████████████████████| 3/3 [00:01<00:00,  2.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performing prediction on 4 slices.\n",
      "Prediction time is: 131.99 ms\n",
      "Prediction results are successfully exported to runs/predict/exp3\n"
     ]
    }
   ],
   "source": [
    "model_path=\"/mnt/e/mw/yolov8-sahi/sahi_note_yolov8/segment/train/weights/best.pt\"\n",
    "model_config_path=\"/mnt/e/mw/yolov8-sahi/sahi_note_yolov8/segment/train/args.yaml\" # agnostic_nms=True in the .yaml file\n",
    "images_dir = \"demo_data/\"\n",
    "\n",
    "predict(\n",
    "model_type=\"yolov8\",\n",
    "model_path=model_path,\n",
    "model_config_path=model_config_path,\n",
    "model_device=\"cuda:0\", # \"cpu\" or 'cuda:0'\n",
    "model_confidence_threshold=0.6,\n",
    "postprocess_class_agnostic=True,\n",
    "source=images_dir,\n",
    "slice_height=640,\n",
    "slice_width=640,\n",
    "overlap_height_ratio=0.2,\n",
    "overlap_width_ratio=0.2,\n",
    "visual_bbox_thickness=1,\n",
    "visual_text_size=0.5,\n",
    "visual_text_thickness=1,\n",
    "export_pickle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "0\n",
      "[ObjectPrediction<\n",
      "    bbox: BoundingBox: <(322, 319, 385, 360), w: 63, h: 41>,\n",
      "    mask: <sahi.annotation.Mask object at 0x7f18eea0eb90>,\n",
      "    score: PredictionScore: <value: 0.83806312084198>,\n",
      "    category: Category: <id: 2, name: car>>, ObjectPrediction<\n",
      "    bbox: BoundingBox: <(450, 306, 497, 345), w: 47, h: 39>,\n",
      "    mask: <sahi.annotation.Mask object at 0x7f1a481f2470>,\n",
      "    score: PredictionScore: <value: 0.8227677941322327>,\n",
      "    category: Category: <id: 2, name: car>>, ObjectPrediction<\n",
      "    bbox: BoundingBox: <(606, 242, 629, 264), w: 23, h: 22>,\n",
      "    mask: <sahi.annotation.Mask object at 0x7f1a481f30d0>,\n",
      "    score: PredictionScore: <value: 0.7479152679443359>,\n",
      "    category: Category: <id: 2, name: car>>, ObjectPrediction<\n",
      "    bbox: BoundingBox: <(834, 307, 873, 341), w: 39, h: 34>,\n",
      "    mask: <sahi.annotation.Mask object at 0x7f18a0217160>,\n",
      "    score: PredictionScore: <value: 0.7018060684204102>,\n",
      "    category: Category: <id: 2, name: car>>, ObjectPrediction<\n",
      "    bbox: BoundingBox: <(382, 280, 421, 302), w: 39, h: 22>,\n",
      "    mask: <sahi.annotation.Mask object at 0x7f18a0244e20>,\n",
      "    score: PredictionScore: <value: 0.6993057727813721>,\n",
      "    category: Category: <id: 2, name: car>>, ObjectPrediction<\n",
      "    bbox: BoundingBox: <(522, 227, 545, 245), w: 23, h: 18>,\n",
      "    mask: <sahi.annotation.Mask object at 0x7f18a02457b0>,\n",
      "    score: PredictionScore: <value: 0.6442450284957886>,\n",
      "    category: Category: <id: 2, name: car>>, ObjectPrediction<\n",
      "    bbox: BoundingBox: <(562, 242, 589, 264), w: 27, h: 22>,\n",
      "    mask: <sahi.annotation.Mask object at 0x7f18a0245120>,\n",
      "    score: PredictionScore: <value: 0.6155170202255249>,\n",
      "    category: Category: <id: 2, name: car>>]\n",
      "7\n",
      "[ObjectPrediction<\n",
      "    bbox: BoundingBox: <(218, 441, 444, 603), w: 226, h: 162>,\n",
      "    mask: <sahi.annotation.Mask object at 0x7f18a0246110>,\n",
      "    score: PredictionScore: <value: 0.8494611382484436>,\n",
      "    category: Category: <id: 7, name: truck>>, ObjectPrediction<\n",
      "    bbox: BoundingBox: <(490, 450, 621, 549), w: 131, h: 99>,\n",
      "    mask: <sahi.annotation.Mask object at 0x7f18a0245f60>,\n",
      "    score: PredictionScore: <value: 0.7154471278190613>,\n",
      "    category: Category: <id: 7, name: truck>>, ObjectPrediction<\n",
      "    bbox: BoundingBox: <(790, 406, 837, 453), w: 47, h: 47>,\n",
      "    mask: <sahi.annotation.Mask object at 0x7f18a0245db0>,\n",
      "    score: PredictionScore: <value: 0.6166358590126038>,\n",
      "    category: Category: <id: 5, name: bus>>]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import pprint\n",
    "\n",
    "obj0 = pickle.load(open('runs/predict/exp/pickles/prediction_visual.pickle', \"rb\"))\n",
    "print(obj0)\n",
    "print(len(obj0))\n",
    "with open(\"runs/predict/exp/pickles/out0.txt\", \"a\") as f:\n",
    "    pprint.pprint(obj0, stream=f)\n",
    "obj1 = pickle.load(open('runs/predict/exp/pickles/small-vehicles1.pickle', \"rb\"))\n",
    "print(obj1)\n",
    "print(len(obj1))\n",
    "with open(\"runs/predict/exp/pickles/out1.txt\", \"a\") as f:\n",
    "    pprint.pprint(obj1, stream=f)\n",
    "obj2 = pickle.load(open('runs/predict/exp/pickles/terrain2.pickle', \"rb\"))\n",
    "print(obj2)\n",
    "print(len(obj2))\n",
    "with open(\"runs/predict/exp/pickles/out2.txt\", \"a\") as f:\n",
    "    pprint.pprint(obj2, stream=f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
